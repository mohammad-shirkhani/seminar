{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CVM_-JMp-YNX",
    "outputId": "311dc7ce-5124-435b-9e5c-97ab55c13ea8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "🗂 مسیر هدف: /content/drive/MyDrive/HotpotQA_snapshot/all_docs.json\n",
      "\n",
      "📏 اندازه فایل: 49.75 MB\n",
      "\n",
      "📥 در حال بارگذاری JSON ...\n",
      "✅ بارگذاری موفق.\n",
      "\n",
      "==== پیش‌نمایش ساختار کلی ====\n",
      "- نوع: dict | تعداد کلیدها: 2\n",
      "  کلید نمونه: 'titles' -> نوع مقدار: list\n",
      "    - نوع: list | طول: 4482\n",
      "      [#0] نوع عضو: str\n",
      "        - مقدار ساده (str): Anthony Avent\n",
      "      [#1] نوع عضو: str\n",
      "        - مقدار ساده (str): Newark, New Jersey\n",
      "      [#2] نوع عضو: str\n",
      "        - مقدار ساده (str): Dražen Dalipagić\n",
      "      ... (4479 عضو دیگر)\n",
      "  کلید نمونه: 'docs' -> نوع مقدار: list\n",
      "    - نوع: list | طول: 4482\n",
      "      [#0] نوع عضو: str\n",
      "        - مقدار ساده (str): Anthony Avent (born October 18, 1969) is an American former professional bask...\n",
      "      [#1] نوع عضو: str\n",
      "        - مقدار ساده (str): Newark (/ˈnjuːərk/ NEW-ərk, locally [nʊəɹk]) is the most populous city in the...\n",
      "      [#2] نوع عضو: str\n",
      "        - مقدار ساده (str): Dražen \"Praja\" Dalipagić (Serbian Cyrillic: Дражен \"Праја\" Далипагић; born ...\n",
      "      ... (4479 عضو دیگر)\n",
      "\n",
      "🔎 دیکشنری با ساختار غیرمتداول / ترکیبی. خروجی پیش‌نمایش را بررسی کنید.\n",
      "\n",
      "✅ تحلیل اولیه انجام شد.\n",
      "\n",
      "📌 خلاصه سریع: نوع ریشه: dict | تعداد کلید: 2 | چند کلید نمونه: ['titles', 'docs']\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import json, os, math, sys\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "FOLDER_NAME = \"HotpotQA_snapshot\"          \n",
    "FILENAME    = \"all_docs.json\"              \n",
    "BASE_PATH   = \"/content/drive/MyDrive\"     \n",
    "FILE_PATH   = os.path.join(BASE_PATH, FOLDER_NAME, FILENAME)\n",
    "\n",
    "SEARCH_IF_NOT_FOUND = True\n",
    "MAX_PREVIEW_ITEMS   = 3    \n",
    "# ==============================================\n",
    "\n",
    "print(\"🗂 مسیر هدف:\", FILE_PATH)\n",
    "\n",
    "def search_file(filename, root=\"/content/drive\"):\n",
    "    matches = []\n",
    "    for dirpath, dirnames, filenames in os.walk(root):\n",
    "        if filename in filenames:\n",
    "            matches.append(os.path.join(dirpath, filename))\n",
    "    return matches\n",
    "\n",
    "if not os.path.isfile(FILE_PATH):\n",
    "    if SEARCH_IF_NOT_FOUND:\n",
    "        print(\"⚠️ فایل در مسیر مستقیم پیدا نشد؛ در حال جستجو...\")\n",
    "        candidates = search_file(FILENAME, BASE_PATH)\n",
    "        if not candidates:\n",
    "            raise FileNotFoundError(f\"فایل {FILENAME} پیدا نشد. مسیر را بررسی کنید.\")\n",
    "        prioritized = [p for p in candidates if FOLDER_NAME in p]\n",
    "        chosen = prioritized[0] if prioritized else candidates[0]\n",
    "        print(\"مسیرهای یافت شده:\")\n",
    "        for i, c in enumerate(candidates, 1):\n",
    "            print(f\"  {i}. {c}\")\n",
    "        print(f\"✅ مسیر انتخاب‌شده: {chosen}\")\n",
    "        FILE_PATH = chosen\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"فایل در مسیر {FILE_PATH} پیدا نشد.\")\n",
    "\n",
    "file_size_mb = os.path.getsize(FILE_PATH) / (1024*1024)\n",
    "print(f\"\\n📏 اندازه فایل: {file_size_mb:.2f} MB\")\n",
    "\n",
    "print(\"\\n📥 در حال بارگذاری JSON ...\")\n",
    "with open(FILE_PATH, \"rb\") as raw:\n",
    "    raw_bytes = raw.read()\n",
    "\n",
    "BOM_UTF8 = b'\\xef\\xbb\\xbf'\n",
    "if raw_bytes.startswith(BOM_UTF8):\n",
    "    print(\"ℹ️ BOM UTF-8 شناسایی شد؛ حذف می‌گردد.\")\n",
    "    raw_bytes = raw_bytes[len(BOM_UTF8):]\n",
    "\n",
    "text_data = raw_bytes.decode(\"utf-8\")\n",
    "\n",
    "data = json.loads(text_data)\n",
    "print(\"✅ بارگذاری موفق.\")\n",
    "\n",
    "def preview_structure(obj, depth=0, max_items=MAX_PREVIEW_ITEMS):\n",
    "    prefix = \"  \" * depth\n",
    "    if isinstance(obj, list):\n",
    "        print(f\"{prefix}- نوع: list | طول: {len(obj)}\")\n",
    "        for i, item in enumerate(obj[:max_items]):\n",
    "            print(f\"{prefix}  [#{i}] نوع عضو: {type(item).__name__}\")\n",
    "            preview_structure(item, depth+2, max_items)\n",
    "        if len(obj) > max_items:\n",
    "            print(f\"{prefix}  ... ({len(obj) - max_items} عضو دیگر)\")\n",
    "    elif isinstance(obj, dict):\n",
    "        print(f\"{prefix}- نوع: dict | تعداد کلیدها: {len(obj)}\")\n",
    "        for i, (k, v) in enumerate(list(obj.items())[:max_items]):\n",
    "            print(f\"{prefix}  کلید نمونه: {repr(k)} -> نوع مقدار: {type(v).__name__}\")\n",
    "            preview_structure(v, depth+2, max_items)\n",
    "        extra = len(obj) - max_items\n",
    "        if extra > 0:\n",
    "            print(f\"{prefix}  ... ({extra} کلید دیگر)\")\n",
    "    else:\n",
    "        s = str(obj)\n",
    "        if len(s) > 80: s = s[:77] + \"...\"\n",
    "        print(f\"{prefix}- مقدار ساده ({type(obj).__name__}): {s}\")\n",
    "\n",
    "def summarize_records(records):\n",
    "    df = pd.DataFrame(records)\n",
    "    print(\"\\nستون‌ها:\", list(df.columns))\n",
    "    print(\"تعداد رکورد:\", len(df))\n",
    "    display(df.head(5))\n",
    "    stats = {}\n",
    "    if \"title\" in df.columns:\n",
    "        stats[\"unique_titles\"] = df[\"title\"].nunique()\n",
    "        stats[\"avg_title_len\"] = df[\"title\"].astype(str).str.len().mean()\n",
    "    text_col = next((c for c in [\"text\", \"content\", \"body\"] if c in df.columns), None)\n",
    "    if text_col:\n",
    "        lengths = df[text_col].astype(str).str.len()\n",
    "        stats.update({\n",
    "            \"text_col\": text_col,\n",
    "            \"avg_text_length\": lengths.mean(),\n",
    "            \"median_text_length\": lengths.median(),\n",
    "            \"min_text_length\": lengths.min(),\n",
    "            \"max_text_length\": lengths.max(),\n",
    "        })\n",
    "    print(\"\\nآمار متنی:\")\n",
    "    for k, v in stats.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "\n",
    "print(\"\\n==== پیش‌نمایش ساختار کلی ====\")\n",
    "preview_structure(data)\n",
    "\n",
    "if isinstance(data, list):\n",
    "    if data and all(isinstance(x, dict) for x in data):\n",
    "        print(\"\\n🔎 تشخیص: لیستی از دیکشنری‌ها (records).\")\n",
    "        summarize_records(data)\n",
    "    elif data and all(isinstance(x, str) for x in data):\n",
    "        print(\"\\n🔎 تشخیص: لیستی از رشته‌ها.\")\n",
    "        print(\"تعداد آیتم‌ها:\", len(data))\n",
    "        print(\"نمونه‌ها:\", data[:5])\n",
    "    else:\n",
    "        print(\"\\n🔎 ساختار لیست ترکیبی/متفاوت است؛ برای تحلیل بیشتر نمونه‌ها را بررسی کنید.\")\n",
    "elif isinstance(data, dict):\n",
    "    if data and all(isinstance(v, str) for v in data.values()):\n",
    "        print(\"\\n🔎 تشخیص: دیکشنری نگاشت title -> text.\")\n",
    "        print(\"تعداد رکورد:\", len(data))\n",
    "        for k, v in list(data.items())[:5]:\n",
    "            print(f\"- عنوان: {k!r} | طول متن: {len(v)}\")\n",
    "    elif any(isinstance(v, list) and v and isinstance(v[0], dict) for v in data.values()):\n",
    "        print(\"\\n🔎 تشخیص: دیکشنری سطح بالا با یک یا چند لیست رکورد.\")\n",
    "        for k, v in data.items():\n",
    "            if isinstance(v, list) and v and isinstance(v[0], dict):\n",
    "                print(f\"\\n> تحلیل لیست رکورد زیر کلید: {k}\")\n",
    "                summarize_records(v)\n",
    "    else:\n",
    "        print(\"\\n🔎 دیکشنری با ساختار غیرمتداول / ترکیبی. خروجی پیش‌نمایش را بررسی کنید.\")\n",
    "else:\n",
    "    print(\"\\n🔎 مقدار ساده‌ی JSON (نه لیست و نه dict):\", type(data).__name__)\n",
    "\n",
    "print(\"\\n✅ تحلیل اولیه انجام شد.\")\n",
    "\n",
    "def quick_summary(obj):\n",
    "    if isinstance(obj, list):\n",
    "        kind = \"list\"\n",
    "        length = len(obj)\n",
    "        elem_types = Counter(type(x).__name__ for x in obj[:100])\n",
    "        return f\"نوع ریشه: list | طول کل: {length} | انواع 100 عضو اول: {dict(elem_types)}\"\n",
    "    if isinstance(obj, dict):\n",
    "        key_count = len(obj)\n",
    "        sample_keys = list(obj.keys())[:5]\n",
    "        return f\"نوع ریشه: dict | تعداد کلید: {key_count} | چند کلید نمونه: {sample_keys}\"\n",
    "    return f\"ریشه نوع ساده: {type(obj).__name__}\"\n",
    "\n",
    "print(\"\\n📌 خلاصه سریع:\", quick_summary(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dhk7YZJXPZ3Y",
    "outputId": "6e920bdc-0349-4a0f-e598-40d816d1e028"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 در حال خواندن فایل ورودی: /content/drive/MyDrive/HotpotQA_snapshot/all_docs.json\n",
      "✅ تعداد رکوردهای اصلی: 4482\n",
      "🔧 در حال تولید قطعات ... (ممکن است کمی زمان ببرد)\n",
      "✅ تعداد کل قطعات: 66237\n",
      "💾 فایل JSON (آرایه‌ای) ذخیره شد: /content/drive/MyDrive/HotpotQA_snapshot/all_docs_chunks.json\n",
      "📏 اندازه فایل خروجی: 64.99 MB\n",
      "\n",
      "🔍 پیش‌نمایش 3 رکورد اول:\n",
      "------------------------------------------------------------\n",
      "id: 0\n",
      "title_chunk: Anthony Avent\n",
      "chunk_index: 1 / 2\n",
      "original_index: 0\n",
      "doc_chunk (کلمات ~150):\n",
      "Anthony Avent (born October 18, 1969) is an American former professional basketball player who was selected by the Atlanta Hawks in the first round (15th pick overall) of the 1991 NBA draft. Born in Rocky Mount, North Carolina, Avent played for the Milwaukee Bucks, Orlando Magic, Vancouver Grizzlies, Utah Jazz and Los Angeles Clippers in six NBA seasons. He played collegiately at Seton Hall Univer...\n",
      "------------------------------------------------------------\n",
      "id: 1\n",
      "title_chunk: Anthony Avent\n",
      "chunk_index: 2 / 2\n",
      "original_index: 0\n",
      "doc_chunk (کلمات ~71):\n",
      "signed a four-year deal with the Bucks, beginning with a $500,000 installment in his first season and increasing in $150,000 increments in each of the succeeding three seasons. Thus, Avent would make $950,000 in the fourth year of his contract. His average salary would be $725,000 per season.In the 1996–97 season he played in several games for the perennially powerful Greek team Panathinaikos, and...\n",
      "------------------------------------------------------------\n",
      "id: 2\n",
      "title_chunk: Newark, New Jersey\n",
      "chunk_index: 1 / 95\n",
      "original_index: 1\n",
      "doc_chunk (کلمات ~150):\n",
      "Newark (/ˈnjuːərk/ NEW-ərk, locally [nʊəɹk]) is the most populous city in the U.S. state of New Jersey and the seat of Essex County. As of the 2020 census, the city's population was 311,549, an increase of 34,409 (+12.4%) from the 2010 census count of 277,140, which in turn reflected an increase of 3,594 (+1.3%) from the 273,546 counted in the 2000 census. The Population Estimates Program calculat...\n",
      "\n",
      "✅ کار تمام شد.\n"
     ]
    }
   ],
   "source": [
    "# Chunking HotpotQA all_docs.json  \n",
    "\n",
    "import os, json\n",
    "from typing import List\n",
    "\n",
    "FOLDER_NAME           = \"HotpotQA_snapshot\"\n",
    "INPUT_FILENAME        = \"all_docs.json\"\n",
    "OUTPUT_FILENAME       = \"all_docs_chunks.json\"      \n",
    "OUTPUT_JSONL_FILENAME = \"all_docs_chunks.jsonl\"     \n",
    "BASE_PATH             = \"/content/drive/MyDrive\"\n",
    "\n",
    "CHUNK_SIZE_WORDS      = 150\n",
    "CHUNK_OVERLAP_WORDS   = 20\n",
    "PRINT_SAMPLE          = 3\n",
    "WRITE_JSON_ARRAY      = True    \n",
    "WRITE_JSONL           = False   \n",
    "# -----------------------------------------\n",
    "\n",
    "INPUT_PATH        = os.path.join(BASE_PATH, FOLDER_NAME, INPUT_FILENAME)\n",
    "OUTPUT_PATH       = os.path.join(BASE_PATH, FOLDER_NAME, OUTPUT_FILENAME)\n",
    "OUTPUT_JSONL_PATH = os.path.join(BASE_PATH, FOLDER_NAME, OUTPUT_JSONL_FILENAME)\n",
    "\n",
    "print(f\"📥 در حال خواندن فایل ورودی: {INPUT_PATH}\")\n",
    "\n",
    "if not os.path.isfile(INPUT_PATH):\n",
    "    raise FileNotFoundError(\"فایل ورودی پیدا نشد.\")\n",
    "\n",
    "with open(INPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "titles = raw.get(\"titles\")\n",
    "docs   = raw.get(\"docs\")\n",
    "\n",
    "if not (isinstance(titles, list) and isinstance(docs, list) and len(titles) == len(docs)):\n",
    "    raise ValueError(\"ساختار فایل مطابق انتظار نیست (لیست‌های titles و docs با طول برابر).\")\n",
    "\n",
    "n_records = len(titles)\n",
    "print(f\"✅ تعداد رکوردهای اصلی: {n_records}\")\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int, overlap: int) -> List[str]:\n",
    "    words = text.split()\n",
    "    n = len(words)\n",
    "    if n == 0:\n",
    "        return []\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < n:\n",
    "        end = start + chunk_size\n",
    "        chunks.append(\" \".join(words[start:end]))\n",
    "        if end >= n:\n",
    "            break\n",
    "        start = end - overlap\n",
    "        if start < 0:\n",
    "            start = 0\n",
    "    return chunks\n",
    "\n",
    "if WRITE_JSONL:\n",
    "    os.makedirs(os.path.dirname(OUTPUT_JSONL_PATH), exist_ok=True)\n",
    "    jsonl_f = open(OUTPUT_JSONL_PATH, \"w\", encoding=\"utf-8\")\n",
    "else:\n",
    "    jsonl_f = None\n",
    "\n",
    "all_chunk_records = [] \n",
    "global_id = 0\n",
    "\n",
    "print(\"🔧 در حال تولید قطعات ... (ممکن است کمی زمان ببرد)\")\n",
    "\n",
    "for original_index, (title, doc) in enumerate(zip(titles, docs)):\n",
    "    chunks = chunk_text(doc, CHUNK_SIZE_WORDS, CHUNK_OVERLAP_WORDS)\n",
    "    total_chunks = len(chunks)\n",
    "    for ci, ch in enumerate(chunks):\n",
    "        rec = {\n",
    "            \"id\": global_id,            # شناسه یکتا\n",
    "            \"title_chunk\": title,       # طبق درخواست\n",
    "            \"doc_chunk\": ch,\n",
    "            \"chunk_index\": ci,\n",
    "            \"total_chunks\": total_chunks,\n",
    "            \"original_index\": original_index\n",
    "        }\n",
    "        if WRITE_JSON_ARRAY:\n",
    "            all_chunk_records.append(rec)\n",
    "        if WRITE_JSONL:\n",
    "            jsonl_f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "        global_id += 1\n",
    "\n",
    "if WRITE_JSONL:\n",
    "    jsonl_f.close()\n",
    "    print(f\"💾 فایل JSONLines ذخیره شد: {OUTPUT_JSONL_PATH}\")\n",
    "\n",
    "print(f\"✅ تعداد کل قطعات: {global_id}\")\n",
    "\n",
    "if WRITE_JSON_ARRAY:\n",
    "    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "    with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f_out:\n",
    "        json.dump(all_chunk_records, f_out, ensure_ascii=False)\n",
    "    out_size_mb = os.path.getsize(OUTPUT_PATH) / (1024*1024)\n",
    "    print(f\"💾 فایل JSON (آرایه‌ای) ذخیره شد: {OUTPUT_PATH}\")\n",
    "    print(f\"📏 اندازه فایل خروجی: {out_size_mb:.2f} MB\")\n",
    "\n",
    "print(f\"\\n🔍 پیش‌نمایش {PRINT_SAMPLE} رکورد اول:\")\n",
    "preview_list = all_chunk_records[:PRINT_SAMPLE] if WRITE_JSON_ARRAY else []\n",
    "if not preview_list and WRITE_JSONL:\n",
    "    with open(OUTPUT_JSONL_PATH, \"r\", encoding=\"utf-8\") as f_preview:\n",
    "        for _ in range(PRINT_SAMPLE):\n",
    "            line = f_preview.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            preview_list.append(json.loads(line))\n",
    "\n",
    "for sample in preview_list:\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"id: {sample['id']}\")\n",
    "    print(f\"title_chunk: {sample['title_chunk']}\")\n",
    "    print(f\"chunk_index: {sample['chunk_index'] + 1} / {sample['total_chunks']}\")\n",
    "    print(f\"original_index: {sample['original_index']}\")\n",
    "    print(f\"doc_chunk (کلمات ~{len(sample['doc_chunk'].split())}):\")\n",
    "    print(sample['doc_chunk'][:400] + (\"...\" if len(sample['doc_chunk']) > 400 else \"\"))\n",
    "\n",
    "print(\"\\n✅ کار تمام شد.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uy2NepVMQayo",
    "outputId": "df387de2-3ce8-42e8-9593-cad68a737dc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "id: 0\n",
      "title_chunk: Anthony Avent\n",
      "chunk_index: 1 / 2\n",
      "original_index: 0\n",
      "doc_chunk (کلمات ~150):\n",
      "Anthony Avent (born October 18, 1969) is an American former professional basketball player who was selected by the Atlanta Hawks in the first round (15th pick overall) of the 1991 NBA draft. Born in Rocky Mount, North Carolina, Avent played for the Milwaukee Bucks, Orlando Magic, Vancouver Grizzlies, Utah Jazz and Los Angeles Clippers in six NBA seasons. He played collegiately at Seton Hall University where he played in the 1989 NCAA championship game. Prior to Seton Hall, Avent played at Malcolm X Shabazz High School in Newark, New Jersey.Upon being drafted 15th overall by the Bucks, Avent went on to instead sign with Phonola Caserta of the Italian League. He made this decision after failing to reach a satisfactory contract with the Bucks. After one season in Italy, Avent signed a four-year deal with the Bucks, beginning with a $500,000 installment in his first season and increasing in $150,000\n",
      "------------------------------------------------------------\n",
      "id: 1\n",
      "title_chunk: Anthony Avent\n",
      "chunk_index: 2 / 2\n",
      "original_index: 0\n",
      "doc_chunk (کلمات ~71):\n",
      "signed a four-year deal with the Bucks, beginning with a $500,000 installment in his first season and increasing in $150,000 increments in each of the succeeding three seasons. Thus, Avent would make $950,000 in the fourth year of his contract. His average salary would be $725,000 per season.In the 1996–97 season he played in several games for the perennially powerful Greek team Panathinaikos, and in 2001 he played for PAOK BC.\n",
      "------------------------------------------------------------\n",
      "id: 2\n",
      "title_chunk: Newark, New Jersey\n",
      "chunk_index: 1 / 95\n",
      "original_index: 1\n",
      "doc_chunk (کلمات ~150):\n",
      "Newark (/ˈnjuːərk/ NEW-ərk, locally [nʊəɹk]) is the most populous city in the U.S. state of New Jersey and the seat of Essex County. As of the 2020 census, the city's population was 311,549, an increase of 34,409 (+12.4%) from the 2010 census count of 277,140, which in turn reflected an increase of 3,594 (+1.3%) from the 273,546 counted in the 2000 census. The Population Estimates Program calculated a population of 305,344 for 2022, making it the 66th-most populous municipality in the nation.Settled in 1666 by Puritans from New Haven Colony, Newark is one of the oldest cities in the United States. Its location at the mouth of the Passaic River (where it flows into Newark Bay) has made the city's waterfront an integral part of the Port of New York and New Jersey. Today, Port Newark–Elizabeth is the primary container shipping terminal of the busiest seaport on the U.S. East\n",
      "\n",
      "✅ کار تمام شد.\n"
     ]
    }
   ],
   "source": [
    "for sample in preview_list:\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"id: {sample['id']}\")\n",
    "    print(f\"title_chunk: {sample['title_chunk']}\")\n",
    "    print(f\"chunk_index: {sample['chunk_index'] + 1} / {sample['total_chunks']}\")\n",
    "    print(f\"original_index: {sample['original_index']}\")\n",
    "    print(f\"doc_chunk (کلمات ~{len(sample['doc_chunk'].split())}):\")\n",
    "    print(sample['doc_chunk'][:])\n",
    "\n",
    "print(\"\\n✅ کار تمام شد.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5iB0MzDDRBEd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
